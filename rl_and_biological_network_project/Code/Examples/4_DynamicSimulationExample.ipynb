{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3952e9f6-751e-4180-91e7-df4f94107ba3",
   "metadata": {},
   "source": [
    "This jupyter notebook teaches you how to create a dynamic (i.e. trained) state reduction object and how to train and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edcf65-93c1-4396-90d0-4572ec09c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.insert(0,str(root_dir))\n",
    "\n",
    "from Gyms.SimulatedNetwork import SimulatedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a528d5-af3f-4c5b-9bef-0fe0022a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the state reduction function\n",
    "from StateReduction.DynamicStatePCA import DynamicStatePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373dba-d31c-4f31-9906-6db506053bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of state and action spaces\n",
    "state_dim  = 4 # Dimension of reduced state space\n",
    "action_dim = 2 # Number of stimuli in action space (each stimulus needs a value of {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc3ef6a-fb75-4834-b6e0-97826997584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object of the state reduction function\n",
    "state = DynamicStatePCA(state_dim=state_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e153a0-a5c9-4873-950b-26cf395f3189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [0. 0. 0. 0.], Reward: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and initialize it\n",
    "env      = SimulatedNetwork(action_dim=action_dim,\n",
    "                            state_dim=state_dim,\n",
    "                            state_object=state) # Use the state object\n",
    "state, _ = env.reset()\n",
    "env.render() # This function gives you the current state + reward, which both is 0 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3224ae1-8590-4fa6-99e3-ca65ce51e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1000 responses to random stimuli for training\n",
    "spikes    = []\n",
    "elecs     = []\n",
    "for i in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    spikes.append(info['spikes'])\n",
    "    elecs.append(info['elecs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8164cc17-2264-405e-90c2-d80ad74c0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your state function (Notice, you are doing this through your environment)\n",
    "env.fit(spikes,elecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e01d04d-21a2-4760-9f81-7bfe2884a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: -1.0\n",
      "State: [[ 0.30628152 -0.15553553  0.00276272  0.36216179]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 0, Avg. reward: -0.5\n",
      "State: [[ 0.09040817 -0.16395798 -0.31297451  0.0827318 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.0\n",
      "State: [[-0.31802051  0.04071407  0.13242686 -0.03005415]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: -0.25\n",
      "State: [[-0.47854874 -0.06397495 -0.50128402  0.23572251]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: -0.2\n",
      "State: [[-0.24976675 -0.13220401 -0.44660677 -0.41375846]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: -0.3333333333333333\n",
      "State: [[-0.34507465  0.15729278 -0.22463936  0.35917431]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.0\n",
      "State: [[-0.25053609 -0.03495259  0.05895596  0.1421187 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [[-0.17522349 -0.50928388 -0.25992651  0.18050469]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [[-0.14235704 -0.17656929 -0.18260014 -0.02490789]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [[-0.05593861 -0.02747686 -0.11550512  0.13303038]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.09090909090909091\n",
      "State: [[ 0.04439245 -0.10200843 -0.36965043 -0.2474491 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.08333333333333333\n",
      "State: [[-0.09162671 -0.09960094 -0.35242825 -0.09447444]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 1, Avg. reward: 0.15384615384615385\n",
      "State: [[-0.25620739 -0.22003223  0.05935911 -0.08514391]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.07142857142857142\n",
      "State: [[-0.26531072 -0.16218888 -0.03501256  0.18898724]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.06666666666666667\n",
      "State: [[-0.14372623  0.04759199 -0.22218259 -0.21980055]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.0\n",
      "State: [[ 0.10217124 -0.14816991 -0.21372832  0.25755356]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [[ 0.10523772 -0.02629871 -0.16580423  0.00329419]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [[-0.24594676  0.08818274 -0.29175139  0.25172528]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.05263157894736842\n",
      "State: [[-0.0585806  -0.07511928 -0.09893328 -0.19327174]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.05\n",
      "State: [[ 0.41965428  0.10348092 -0.13640698  0.23503318]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.0\n",
      "State: [[ 0.32645772 -0.06282011  0.35897888 -0.0591843 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -2, Avg. reward: -0.09090909090909091\n",
      "State: [[-0.4289793   0.03754965 -0.24209059 -0.06389478]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.0\n",
      "State: [[-0.18263343  0.02564809  0.15668727  0.11552364]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 1, Avg. reward: 0.041666666666666664\n",
      "State: [[-0.36804517  0.33755646 -0.2728276  -0.26991048]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 2]\n",
      "Reward: -1, Avg. reward: 0.0\n",
      "State: [[-0.55790737 -0.12505482  0.05641163  0.50493086]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: -1, Avg. reward: -0.038461538461538464\n",
      "State: [[ 0.08968454  0.11954339 -0.06453119  0.09905803]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: -0.037037037037037035\n",
      "State: [[-0.00398139 -0.05380995  0.02661712  0.08322899]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.03571428571428571\n",
      "State: [[ 0.11662839 -0.40982761 -0.46845956  0.02536708]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.06896551724137931\n",
      "State: [[-0.23088488 -0.05773941 -0.33244477 -0.10125006]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.06666666666666667\n",
      "State: [[-0.14287197 -0.11341652 -0.37707462 -0.20040512]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.03225806451612903\n",
      "State: [[-0.37090697  0.13164923 -0.11204981  0.13612122]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: -1, Avg. reward: 0.0\n",
      "State: [[ 0.2429875  -0.1806967   0.19899286 -0.02833338]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.030303030303030304\n",
      "State: [[-0.25005776  0.08691598 -0.08777329  0.01350941]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.029411764705882353\n",
      "State: [[0.053885   0.07183805 0.13459208 0.24176307]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.0\n",
      "State: [[-0.16174323 -0.24327446 -0.33389325 -0.11270847]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.027777777777777776\n",
      "State: [[-0.03739148 -0.04033398  0.26532312  0.0201806 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.05405405405405406\n",
      "State: [[-0.23088488 -0.05773941 -0.33244477 -0.10125006]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.05263157894736842\n",
      "State: [[ 0.16562773  0.21187996  0.0764968  -0.16114959]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.07692307692307693\n",
      "State: [[-0.3077452  -0.40363651 -0.09679941  0.158738  ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.075\n",
      "State: [[-0.37211898 -0.02132856  0.00911914  0.39471112]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.12195121951219512\n",
      "State: [[-0.1256177  -0.13281382 -0.32464121 -0.00052513]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.14285714285714285\n",
      "State: [[-0.18025598 -0.02215544 -0.09255687  0.16423633]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.16279069767441862\n",
      "State: [[-0.19707417 -0.13767999 -0.45098422  0.21322539]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.20454545454545456\n",
      "State: [[ 0.17449478 -0.2841796  -0.3604846   0.18390117]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.2\n",
      "State: [[-0.26573217 -0.08085781 -0.08563765  0.098019  ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 0, Avg. reward: 0.1956521739130435\n",
      "State: [[-0.1307628  -0.51958693 -0.1709028   0.27671895]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.2127659574468085\n",
      "State: [[-0.13299256 -0.10351519 -0.22895175  0.0843244 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.20833333333333334\n",
      "State: [[-0.21939396  0.11366308 -0.21409693  0.16757538]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 0, Avg. reward: 0.20408163265306123\n",
      "State: [[ 0.14801429 -0.20735424 -0.06107115  0.12094051]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: -1, Avg. reward: 0.18\n",
      "State: [[-0.12102261 -0.51327065 -0.13821923  0.2215047 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.17647058823529413\n",
      "State: [[ 0.18361121 -0.06129669  0.19249468 -0.28334071]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 0, Avg. reward: 0.17307692307692307\n",
      "State: [[ 0.38651942 -0.03927002 -0.0792568   0.03019368]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 1, Avg. reward: 0.18867924528301888\n",
      "State: [[ 0.06472235 -0.01881533 -0.01150426 -0.57591768]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 0, Avg. reward: 0.18518518518518517\n",
      "State: [[-0.10571171 -0.51931946 -0.16498236  0.00826734]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.18181818181818182\n",
      "State: [[-0.05136863 -0.00792624 -0.21896175 -0.19015218]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.19642857142857142\n",
      "State: [[-0.09549367 -0.43655218 -0.13214499  0.0592601 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 2, Avg. reward: 0.22807017543859648\n",
      "State: [[ 0.06282755  0.29427628 -0.43846813  0.18429467]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.25862068965517243\n",
      "State: [[-0.19214202 -0.32919621 -0.10234456  0.1816351 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.2542372881355932\n",
      "State: [[-0.12517973 -0.29901284 -0.12720018 -0.08382271]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.25\n",
      "State: [[0.053885   0.07183805 0.13459208 0.24176307]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.2459016393442623\n",
      "State: [[-0.26516692  0.0320947  -0.09711069  0.00493611]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.25806451612903225\n",
      "State: [[-0.21147779 -0.41650894 -0.18813339 -0.15135298]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 0, Avg. reward: 0.25396825396825395\n",
      "State: [[-0.19446474 -0.12271913 -0.61371094 -0.3975195 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.265625\n",
      "State: [[-0.09513108  0.17297723 -0.37771659 -0.14951621]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.27692307692307694\n",
      "State: [[-0.15274614 -0.46266148 -0.08031613  0.22822026]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: -1, Avg. reward: 0.25757575757575757\n",
      "State: [[-0.37462987 -0.27585377 -0.20710443  0.01252595]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.2537313432835821\n",
      "State: [[-0.02248657 -0.06825033  0.00544199  0.08980313]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 0, Avg. reward: 0.25\n",
      "State: [[ 0.08892887 -0.24395139 -0.08455117  0.08084928]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.2463768115942029\n",
      "State: [[-0.42998537 -0.14697656 -0.09885582  0.23617704]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.24285714285714285\n",
      "State: [[ 0.10523772 -0.02629871 -0.16580423  0.00329419]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.22535211267605634\n",
      "State: [[-0.4132273   0.15480692 -0.10279332  0.15824006]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 0, Avg. reward: 0.2222222222222222\n",
      "State: [[-0.16902895 -0.20139867 -0.33957339  0.01392951]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.2328767123287671\n",
      "State: [[-0.05822417 -0.09224783 -0.45053804 -0.32554118]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: -1, Avg. reward: 0.21621621621621623\n",
      "State: [[-0.0123784   0.09486604 -0.34796121 -0.21555834]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.2\n",
      "State: [[0.1450149  0.05308925 0.17842304 0.21325525]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 1, Avg. reward: 0.21052631578947367\n",
      "State: [[ 0.08087124  0.03275813 -0.0416806   0.23924461]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.19480519480519481\n",
      "State: [[-0.22772863 -0.29538887 -0.11896067 -0.15666647]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.20512820512820512\n",
      "State: [[-0.17897408  0.06478797 -0.02256535 -0.07069563]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 1, Avg. reward: 0.21518987341772153\n",
      "State: [[-0.15254834 -0.17910297 -0.30852765 -0.14945279]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.2\n",
      "State: [[ 0.56881339 -0.15834455 -0.2443301  -0.12812549]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.20987654320987653\n",
      "State: [[0.24945393 0.02129667 0.03708352 0.20505062]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 0, Avg. reward: 0.2073170731707317\n",
      "State: [[ 0.31490113 -0.32486476 -0.07405077 -0.17367797]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.20481927710843373\n",
      "State: [[-0.26755203  0.17820903 -0.21413604 -0.24367469]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.21428571428571427\n",
      "State: [[ 0.13438375 -0.08938959 -0.17553882  0.34017785]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.2235294117647059\n",
      "State: [[ 0.06799716 -0.0533909  -0.3254275  -0.1616874 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.22093023255813954\n",
      "State: [[-0.04844208 -0.0435069  -0.06240659 -0.01298527]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 3, Avg. reward: 0.25287356321839083\n",
      "State: [[-0.07045093 -0.18494727 -0.31042462  0.14857634]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.23863636363636365\n",
      "State: [[ 0.01398832 -0.03847052  0.385275    0.05527652]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.23595505617977527\n",
      "State: [[-0.18915446  0.11791006 -0.15411217  0.19196969]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.24444444444444444\n",
      "State: [[-0.2267709  -0.41547828 -0.26947741 -0.0399782 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.24175824175824176\n",
      "State: [[ 0.13821981 -0.14075553 -0.20150972  0.1109421 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.2391304347826087\n",
      "State: [[-0.16733095 -0.00102554 -0.26640552 -0.30556225]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.24731182795698925\n",
      "State: [[-0.22496513  0.19913091  0.23078501  0.66455122]]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.24468085106382978\n",
      "State: [[-0.18612443 -0.08733966 -0.34121889  0.06934539]]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.25263157894736843\n",
      "State: [[ 0.2254707  -0.32896208 -0.30347112 -0.12579745]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.25\n",
      "State: [[-0.17522349 -0.50928388 -0.25992651  0.18050469]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.25773195876288657\n",
      "State: [[-0.17871697 -0.08031964 -0.07494055  0.2257603 ]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: -1, Avg. reward: 0.24489795918367346\n",
      "State: [[ 0.07814036 -0.58409516 -0.12829191 -0.12092945]]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: -1, Avg. reward: 0.23232323232323232\n",
      "State: [[ 0.38731691  0.04607658  0.29832038 -0.31255477]]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.24\n",
      "State: [[ 0.0173688  -0.36038477 -0.04418782  0.0586964 ]]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example code, that stimulates the network 100 times with a randomly sampled action, while calculating also the average reward received\n",
    "\n",
    "total_reward = 0\n",
    "action_count = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # For simplicity, choose a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Stimulate with action: {action}\")\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    action_count += 1\n",
    "\n",
    "    print(f\"Reward: {reward}, Avg. reward: {total_reward/action_count}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "    # If you want a more complete plotting of each step\n",
    "    # env.render()\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4ecccb-a597-4505-b3a2-6881380908e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 0.24\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average reward: {total_reward/action_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b196e07-6449-41e3-9e51-5097d5c068b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
