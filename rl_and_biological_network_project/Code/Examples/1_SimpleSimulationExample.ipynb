{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c558ea-7f5e-4b4d-a339-7a89e6778290",
   "metadata": {},
   "source": [
    "This jupyter gives you a simple example of how you should use the Simulated Network (asynchronous) environment. This environment is not meant as a training ground of your algorithms, but only to check whether or not your algorithm can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92edcf65-93c1-4396-90d0-4572ec09c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.insert(0,str(root_dir))\n",
    "\n",
    "from Gyms.SimulatedNetwork import SimulatedNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a528d5-af3f-4c5b-9bef-0fe0022a21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define size of state and action spaces\n",
    "state_dim  = 4 # Dimension of reduced state space\n",
    "action_dim = 2 # Number of stimuli in action space (each stimulus needs a value of {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5373dba-d31c-4f31-9906-6db506053bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [0. 0. 0. 0.], Reward: 0\n"
     ]
    }
   ],
   "source": [
    "# Create environment and initialize it\n",
    "env      = SimulatedNetwork(action_dim=action_dim,state_dim=state_dim)\n",
    "state, _ = env.reset()\n",
    "env.render() # This function gives you the current state + reward, which both is 0 after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5b3b3f7-8dc7-455f-bf05-df02d2ef95a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([5 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the action space dimensions\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75680da-4bd1-40b1-a3fe-607e070a5c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the state space dimensions\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc3ef6a-fb75-4834-b6e0-97826997584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can now for example get a random action:\n",
    "action = env.action_space.sample()\n",
    "action\n",
    "# This action can then be applied to the environment with:\n",
    "# state, reward, terminated, truncated, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ab4df5-8dc2-4e62-98f8-9fbda33eb750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5fdf0f-126b-49b9-bef0-79070d77b764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0.]),\n",
       " 0,\n",
       " False,\n",
       " False,\n",
       " {'spikes': [],\n",
       "  'elecs': [],\n",
       "  'action': array([0, 0]),\n",
       "  'missed_cyc': 0,\n",
       "  'stim_id': 1,\n",
       "  'simulated': True,\n",
       "  'comment': 'none'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a4cc22-d672-490f-93c6-d98b3ca82de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [ 0.5        -0.53323067  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [-0.5        -0.31378865  0.66022465  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.0\n",
      "State: [-1.         -0.44056442  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.5\n",
      "State: [-0.5        -0.42792942 -0.03327589  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.6\n",
      "State: [ 0.         -0.40983504  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.5\n",
      "State: [-0.5        -0.42266368  0.0876144   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.2857142857142857\n",
      "State: [-1.          0.          0.28910005  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 0, Avg. reward: 0.25\n",
      "State: [ 0.5        -0.29341869  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 1, Avg. reward: 0.3333333333333333\n",
      "State: [-0.5         0.         -0.33453441  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.3\n",
      "State: [-1.         -0.40295023  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 0, Avg. reward: 0.2727272727272727\n",
      "State: [-1.         -0.46472191  0.13531366  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.3333333333333333\n",
      "State: [ 0.5         0.         -0.08487998  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.3076923076923077\n",
      "State: [-0.5        -0.41941808  0.08285227  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.2857142857142857\n",
      "State: [-0.5        -0.39475193  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 4]\n",
      "Reward: 1, Avg. reward: 0.3333333333333333\n",
      "State: [ 0.5         0.         -0.18909756  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.375\n",
      "State: [ 0.5        -0.26836325  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.4117647058823529\n",
      "State: [ 0.          0.         -0.20102127  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.3888888888888889\n",
      "State: [-1.        -0.3663031  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 1, Avg. reward: 0.42105263157894735\n",
      "State: [-1.          0.         -0.27331964  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.5\n",
      "State: [-1.         -0.40809334 -0.22217293  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 1]\n",
      "Reward: 0, Avg. reward: 0.47619047619047616\n",
      "State: [-1.         -0.34364666  0.24267197  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.45454545454545453\n",
      "State: [-0.5        -0.36473193  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 2, Avg. reward: 0.5217391304347826\n",
      "State: [ 0.5        -0.37592931 -0.2899233   0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 0]\n",
      "Reward: 0, Avg. reward: 0.5\n",
      "State: [ 0.         -0.48640908  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 0]\n",
      "Reward: 0, Avg. reward: 0.48\n",
      "State: [-0.5  0.   0.   0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 0, Avg. reward: 0.46153846153846156\n",
      "State: [-1.         -0.31591428 -0.15611246  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 1, Avg. reward: 0.48148148148148145\n",
      "State: [-0.5  0.   0.   0. ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.5\n",
      "State: [-1.         -0.38187065  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.5172413793103449\n",
      "State: [-0.5        -0.42906139  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.5333333333333333\n",
      "State: [-1.         -0.39267417  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.5483870967741935\n",
      "State: [ 0.         -0.44342244  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.5625\n",
      "State: [-0.5        -0.36786581  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.5757575757575758\n",
      "State: [ 0.5        -0.35948579  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 1]\n",
      "Reward: 2, Avg. reward: 0.6176470588235294\n",
      "State: [ 0.         -0.45674117 -0.09276842  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.6\n",
      "State: [-0.5        -0.39913203  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.5555555555555556\n",
      "State: [0.5       0.4664442 0.        0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.5405405405405406\n",
      "State: [ 0.         -0.29895283  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.5263157894736842\n",
      "State: [-0.5        -0.25588706  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 2, Avg. reward: 0.5641025641025641\n",
      "State: [-1.         -0.35503207  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.55\n",
      "State: [-0.5        -0.48299612  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.5609756097560976\n",
      "State: [-1.         -0.42456779  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.5238095238095238\n",
      "State: [-1.          0.          0.18563671  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: 2, Avg. reward: 0.5581395348837209\n",
      "State: [ 0.5        -0.45872047 -0.20459623  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: 1, Avg. reward: 0.5681818181818182\n",
      "State: [-1.        -0.3820904  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.5555555555555556\n",
      "State: [ 0.         -0.52552711  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.5217391304347826\n",
      "State: [0.5        0.         0.18045171 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 0, Avg. reward: 0.5106382978723404\n",
      "State: [-0.5        -0.28769022  0.18764661  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.5208333333333334\n",
      "State: [0. 0. 0. 0.]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.5102040816326531\n",
      "State: [ 0.5        -0.28009033  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 0, Avg. reward: 0.5\n",
      "State: [ 0.5         0.         -0.17266082  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: -1, Avg. reward: 0.47058823529411764\n",
      "State: [0.5        0.21379925 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.4423076923076923\n",
      "State: [0.5        0.         0.22127761 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.4339622641509434\n",
      "State: [-1.         -0.44661283  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.46296296296296297\n",
      "State: [-0.5        -0.28989252 -0.15888441  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.4727272727272727\n",
      "State: [ 0.          0.         -0.23126731  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.4642857142857143\n",
      "State: [-0.5        -0.35994248  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 1, Avg. reward: 0.47368421052631576\n",
      "State: [0.5        0.36994132 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.4827586206896552\n",
      "State: [ 0.         -0.13293961 -0.03526399  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.4745762711864407\n",
      "State: [-0.5        -0.36831949  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.4666666666666667\n",
      "State: [ 0.         -0.42109663  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 4]\n",
      "Reward: 1, Avg. reward: 0.47540983606557374\n",
      "State: [ 0.5        -0.3573593  -0.41412777  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 2]\n",
      "Reward: 1, Avg. reward: 0.4838709677419355\n",
      "State: [-0.5         0.         -0.16232118  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.5079365079365079\n",
      "State: [-0.5        -0.31697746 -0.22922443  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.515625\n",
      "State: [ 0.5        -0.39238633  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.5076923076923077\n",
      "State: [ 0.         -0.33335033  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.48484848484848486\n",
      "State: [-0.5         0.          0.16267591  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.4925373134328358\n",
      "State: [-1.         -0.19793192  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 3]\n",
      "Reward: 0, Avg. reward: 0.4852941176470588\n",
      "State: [0.5        0.33095716 0.         0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 4]\n",
      "Reward: 1, Avg. reward: 0.4927536231884058\n",
      "State: [ 0.         -0.37075439  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 0, Avg. reward: 0.4857142857142857\n",
      "State: [-1.         -0.47118154  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 1]\n",
      "Reward: 1, Avg. reward: 0.49295774647887325\n",
      "State: [-1.          0.         -0.43342684  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 2]\n",
      "Reward: -1, Avg. reward: 0.4722222222222222\n",
      "State: [0.5        0.         0.14159414 0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 0, Avg. reward: 0.4657534246575342\n",
      "State: [-0.5         0.          0.28869123  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: 2, Avg. reward: 0.4864864864864865\n",
      "State: [-0.5        -0.30246238 -0.26150996  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: -2, Avg. reward: 0.4533333333333333\n",
      "State: [-0.5         0.          0.41089176  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: 0, Avg. reward: 0.4473684210526316\n",
      "State: [-1.         -0.10700943 -0.41181466  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 1]\n",
      "Reward: 1, Avg. reward: 0.45454545454545453\n",
      "State: [ 0.5        -0.42110041  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.46153846153846156\n",
      "State: [-0.5        -0.41433189  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.46835443037974683\n",
      "State: [-0.5        -0.18353588  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 0]\n",
      "Reward: 0, Avg. reward: 0.4625\n",
      "State: [-1.         -0.37391359  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [3 3]\n",
      "Reward: 1, Avg. reward: 0.4691358024691358\n",
      "State: [ 0.          0.         -0.17508859  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.4634146341463415\n",
      "State: [ 0.5        -0.46007144  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.4578313253012048\n",
      "State: [-0.5      -0.278041  0.        0.      ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.4523809523809524\n",
      "State: [-0.5        -0.43534841  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.43529411764705883\n",
      "State: [-0.5         0.          0.10817738  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 3]\n",
      "Reward: 0, Avg. reward: 0.43023255813953487\n",
      "State: [ 0.         -0.26381677  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 2]\n",
      "Reward: 1, Avg. reward: 0.4367816091954023\n",
      "State: [-1.         -0.40924976  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 0]\n",
      "Reward: 0, Avg. reward: 0.4318181818181818\n",
      "State: [-0.5        -0.38503476  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: -1, Avg. reward: 0.4157303370786517\n",
      "State: [-0.5        0.3244715  0.         0.       ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 3]\n",
      "Reward: -1, Avg. reward: 0.4\n",
      "State: [-1.          0.          0.20936262  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.3956043956043956\n",
      "State: [ 0.5        -0.27734712  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 1, Avg. reward: 0.40217391304347827\n",
      "State: [ 0.5        -0.41983529 -0.34890394  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: 0, Avg. reward: 0.3978494623655914\n",
      "State: [-0.5        -0.50419163  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [0 2]\n",
      "Reward: -1, Avg. reward: 0.3829787234042553\n",
      "State: [-0.5        -0.44607135  0.36072821  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [1 4]\n",
      "Reward: -1, Avg. reward: 0.3684210526315789\n",
      "State: [-1.          0.45901393  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.3645833333333333\n",
      "State: [ 0.5        -0.29408855  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 3]\n",
      "Reward: 1, Avg. reward: 0.3711340206185567\n",
      "State: [-0.5        -0.42287875  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 1]\n",
      "Reward: 1, Avg. reward: 0.37755102040816324\n",
      "State: [-0.5        -0.25659903  0.          0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [2 4]\n",
      "Reward: -1, Avg. reward: 0.36363636363636365\n",
      "State: [-0.5         0.          0.20418687  0.        ]\n",
      "-----------------------------\n",
      "Stimulate with action: [4 0]\n",
      "Reward: 0, Avg. reward: 0.36\n",
      "State: [ 0.5        -0.45574348  0.          0.        ]\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example code, that stimulates the network 100 times with a randomly sampled action, while calculating also the average reward received\n",
    "\n",
    "total_reward = 0\n",
    "action_count = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    # For simplicity, choose a random action\n",
    "    action = env.action_space.sample()\n",
    "    print(f\"Stimulate with action: {action}\")\n",
    "    \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    action_count += 1\n",
    "\n",
    "    print(f\"Reward: {reward}, Avg. reward: {total_reward/action_count}\")\n",
    "    print(f\"State: {state}\")\n",
    "\n",
    "    # If you want a more complete plotting of each step\n",
    "    # env.render()\n",
    "\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e01d04d-21a2-4760-9f81-7bfe2884a916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spikes': array([4.36079365, 9.55334654]),\n",
       " 'elecs': array([3, 0]),\n",
       " 'action': array([4, 0]),\n",
       " 'missed_cyc': 0,\n",
       " 'stim_id': 101,\n",
       " 'simulated': True,\n",
       " 'comment': 'none'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9908809f-ad71-4ed0-9d67-9ce4eeaabe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 0.36\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average reward: {total_reward/action_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20356d-4406-4b66-bd7d-9f6fb07b2292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
