{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cb7facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d622c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(filename):\n",
    "    \"\"\"\n",
    "    Load a dictionary of graphs from JSON file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as file_handle:\n",
    "        string_dict = json.load(file_handle)\n",
    "    return _load_data_from_string_dict(string_dict)\n",
    "\n",
    "def _load_data_from_string_dict(string_dict):\n",
    "    \"\"\"\n",
    "    Internal helper to parse graphs from node-link JSON format.\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    for key in string_dict:\n",
    "        data = copy.deepcopy(string_dict[key])\n",
    "        if 'edges' in data:\n",
    "            data[\"links\"] = data.pop(\"edges\")\n",
    "        graph = nx.node_link_graph(data)\n",
    "        result_dict[key] = graph\n",
    "    return result_dict\n",
    "\n",
    "def write_data_to_json_file(graph_dict, filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Write dictionary of graphs to JSON file.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as file_handle:\n",
    "        json_string = json.dumps(graph_dict, default=nx.node_link_data, **kwargs)\n",
    "        file_handle.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f173b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_duplicates(input_file, output_file):\n",
    "    # Load the input graph data\n",
    "    train_data = load_data_from_file(input_file)\n",
    "\n",
    "    # List to hold all graphs and names\n",
    "    training_graphs = []\n",
    "    training_graph_names = []\n",
    "\n",
    "    # Process each graph in the training data\n",
    "    for i in range(len(train_data)):  # For each graph in the training set\n",
    "        mol = list(train_data.keys())[i]\n",
    "        graph = train_data[mol]  # Graph to be duplicated\n",
    "        \n",
    "        # Get the target nodes (with orbitals, even if they are -1)\n",
    "        target_node_indices = [n for n, v in graph.nodes(data=True) if v['orbitals']]\n",
    "\n",
    "        # List to hold all duplicated graphs and names for this graph\n",
    "        all_graphs = []\n",
    "        all_names = []\n",
    "\n",
    "        count = 0\n",
    "        for n_i in target_node_indices:  # For each target node\n",
    "            graph_i = graph.copy()\n",
    "\n",
    "            # Print orbitals for inspection before filtering\n",
    "            #print(f\"Processing molecule {mol}: Node {n_i} orbitals before filtering: {graph_i.nodes[n_i]['orbitals']}\")\n",
    "\n",
    "            # Add 'NONE' bonds to all non-neighboring nodes of the target node\n",
    "            for nb_i in nx.non_neighbors(graph_i, n_i):\n",
    "                graph_i.add_edge(n_i, nb_i, bond_type='NONE')  # Add edge to target node\n",
    "            \n",
    "            # Create duplicates for each orbital of the target node, including those with -1\n",
    "            for j in range(len(graph_i.nodes[n_i]['orbitals'])):\n",
    "                graph_ij = graph_i.copy()\n",
    "\n",
    "                # No skipping based on orbital value now\n",
    "                graph_ij.nodes[n_i]['orbitals'] = [graph_ij.nodes[n_i]['orbitals'][j]]\n",
    "\n",
    "                # Print orbitals after filtering for comparison\n",
    "                #print(f\"Processing molecule {mol}: Node {n_i} orbitals after filtering: {graph_ij.nodes[n_i]['orbitals']}\")\n",
    "\n",
    "                # Mark the target node and other nodes\n",
    "                graph_ij.nodes[n_i]['target'] = True\n",
    "                for n in graph_ij.nodes:\n",
    "                    if n != n_i:\n",
    "                        graph_ij.nodes[n]['target'] = False\n",
    "                \n",
    "                # Append the duplicated graph and its name\n",
    "                all_graphs.append(graph_ij)\n",
    "                name = f\"{mol}_{n_i}_{j}\"  # Name based on molecule, target node, and orbital index\n",
    "                all_names.append(name)\n",
    "                count += 1\n",
    "\n",
    "        # Add the generated graphs and names to the overall lists\n",
    "        training_graphs.extend(all_graphs)\n",
    "        training_graph_names.extend(all_names)\n",
    "\n",
    "        # Print how many duplicates were created for this graph\n",
    "        #print(f\"Graph {i} for molecule {mol} created {count} duplicates.\")\n",
    "\n",
    "    # Write the duplicates to a new JSON file\n",
    "    training_data_dict = dict(zip(training_graph_names, training_graphs))\n",
    "    write_data_to_json_file(training_data_dict, output_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50374100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 0 for molecule [Ag] created 1 duplicates.\n",
      "Graph 1 for molecule C/C(=C\\C(=O)C(F)(F)F)/O[Al](O/C(=C\\C(=O)C(F)(F)F)/C)O/C(=C\\C(=O)C(F)(F)F)/C created 31 duplicates.\n",
      "Graph 2 for molecule C(=C(\\O[Al](O/C(=C\\C(=O)C(F)(F)F)/C(F)(F)F)O/C(=C\\C(=O)C(F)(F)F)/C(F)(F)F)/C(F)(F)F)\\C(=O)C(F)(F)F created 40 duplicates.\n",
      "Graph 3 for molecule C/C(=C/C(=O)C)/O[Al](O/C(=C\\C(=O)C)/C)O/C(=C\\C(=O)C)/C created 22 duplicates.\n",
      "Graph 4 for molecule CC(/C(=C/C(=O)C(C)(C)C)/O[Al](O/C(=C\\C(=O)C(C)(C)C)/C(C)(C)C)O/C(=C\\C(=O)C(C)(C)C)/C(C)(C)C)(C)C created 40 duplicates.\n"
     ]
    }
   ],
   "source": [
    "create_duplicates('graph_data.json', 'graph_data_duplicates.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5abfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
